{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Harsha/Desktop\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/Harsha/Desktop/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('hours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours  Scores\n",
       "0    2.5      21\n",
       "1    5.1      47\n",
       "2    3.2      27\n",
       "3    8.5      75\n",
       "4    3.5      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZQV9ZnG8e8joDSoQQQNiywZCWpExbREJDqMC45xY5w4mMSEOCbo6DEaR0fMZuIcRz1mxjgTY0LUkZm4G8V1EgzglsSlASMqKolxoSHSGhBQjKLv/FF18dL2Ut123fX5nNOnb9WtW/X2Fd9b961fvT9FBGZmVj+2KHcAZmZWWk78ZmZ1xonfzKzOOPGbmdUZJ34zszrjxG9mVmec+M3M6owTv/UYSS9IOrjVui9LeqhcMfWk9G95V9J6SWslPS7piHLHVayW3m/LjxO/VSVJvct06N9GxNbAAOAq4CZJA7uygzLGbgY48VuJSdpV0n2S1kh6StJRRc/dJ+krRcubnb1KCkmnSloGLFPiUkmrJL0u6QlJu7dxzOMkNbVa93VJd6SPPyPpaUnrJDVLOquzvyMi3gOuBhqAj6X7OSL9FrBG0m8k7VF0vBcknSPpCeANSb0l7STpVkktkl6T9MOi7f9R0lJJqyX9UtLIVu/DyZKWpc9fnr4XuwI/Biam30rWpNsfLmlx+i3lZUnfbfVefEnSi2kM3y7+5iZpC0kzJf0hfb7LH3RWeZz4rWQk9QHuBOYCOwCnAddKGtuF3UwFPgXsBkwBDgA+TnIGPg14rY3X3AGMlTSmaN3ngevSx1cBJ0XENsDuwPwMf0tv4CvAepIPob1JPghOArYHfgLcIWmropd9Djg8jTWAu4AXgVHAMOCGdN9TgW8AxwCDgQeB61uFcASwD7An8A/AoRGxFDiZ9FtJRAxIt30D+FJ63MOBf0qPgaTdgB8BXwCGAB9JYyn4Gsl7/tfAUGA1cHln749VuIjwj3965Ad4gSQRrin6eRN4KH1+f+BPwBZFr7ke+G76+D7gK0XPfbnw2nQ5gAOLlg8EngP2Ld5nO7H9DPhO+ngMsA7oly6/RJKwt+1kH18GNqZ/16vAw8DB6XNXAP/aavtngb8uem/+sei5iUAL0LuN4/wfcGLR8hbp+ziy6H34dNHzNwEz23rP2vk7fgBcmj7+DnB90XP9gLeL/q6lwEFFzw8B3mkrbv9Uz4/P+K2nTY2IAYUf4JSi54YCL0dSJil4kc3PMDvzcuFBRMwHfkhyBvqKpFmStm3nddeRnHFDcrY/JyLeTJf/HvgM8KKk+yVN7OD4D6d/26CI2DcifpWuHwn8c1rmWZOWWXYi+Zs/EHv63IsRsbGNY4wELivaz58Bsfn79Keix28CW7cXsKRPSVqQlpReJ/lWMCh9eiibv6dvsvm3ppHAbUWxLAXeBXZs73hW+Zz4rZRWADtJKv53NwJoTh+/QXLGWfDRNvaxWTvZiPjPiPgk8AmSks/Z7Rx7LjBI0l4kHwCFMg8R8VhEHE1SfppDcgbdVS8DFxR/6EVEv4goLtFEq+1HtHOh92WS0lPxvhoi4jcZ4mir3e51JOWunSLiIyTXAZQ+txIYXthQUgNJqao4lsNaxdI3IpqxquXEb6X0CEly/xdJfSRNBo4krW0DjwPHSOonaWfgxI52Jmmf9Gy2T7rft0jORj8gPbO+BbgEGAjcm+5jS0lfkPSRiHgHWNvePjrxU+DkNB5J6p9eVN2mne0fJUm6F6Xb9pU0KX3ux8C5kj6RxvgRScdmjOMVYLikLYvWbQP8OSLekjSB5BtPwS3AkZL2S1/zPd7/UCjEckHh4rKkwZKOzhiLVSgnfiuZiHgbOAo4jKRG/iPgSxHxTLrJpST15VeA2cC1nexyW5KEu5qkZPQa8P0Otr8OOBi4uVWJ5YvAC5LWkpRBju/CnwVARDQBXyUpPa0Gfk9Sb29v+3dJPvR2JrnGsJzk4jQRcRtwMXBDGtOTJO9ZFvOBp4A/SXo1XXcKcL6kdSQ1/U3faCLiKZKL7DeQfBCtA1YBf0k3uYzk28Lc9PUPk1xctyqmCE/EYmYJSVuTXLweExF/LHc8lg+f8ZvVOUlHpuW1/iTfmJaQjEKyGuXEb2ZHk1x4X0Ey1PW4cCmgprnUY2ZWZ3zGb2ZWZ6qiWdSgQYNi1KhR5Q7DzKyqLFy48NWIGNx6fVUk/lGjRtHU1NT5hmZmtomkF9ta71KPmVmdceI3M6szTvxmZnWmKmr8bXnnnXdYvnw5b731VrlDqQh9+/Zl+PDh9OnTp9yhmFmFq9rEv3z5crbZZhtGjRqFpM5fUMMigtdee43ly5czevTocodjZhWuahP/W2+95aSfksT2229PS0tLuUMxs3bMWdzMJb98lhVrNjB0QANnHzqWqeO7MhVFz6naxA846Rfxe2FWueYsbubcW5ew4Z2k43fzmg2ce+sSgLIkf1/cNTPL2SW/fHZT0i/Y8M67XPLLZ8sSjxP/h3DBBRfwiU98gj322IO99tqLRx55pNwhmVkFWrFmQ5fW562qSz1d0dP1td/+9rfcddddLFq0iK222opXX32Vt99+u9v727hxI717181/DrO6MnRAA81tJPmhAxrKEE2dnPEX6mvNazYQvF9fm7O4+9OGrly5kkGDBrHVVlsBMGjQIIYOHcpjjz3Gfvvtx5577smECRNYt24db731FieccALjxo1j/PjxLFiwAIBrrrmGY489liOPPJIpU6YAcMkll7DPPvuwxx57cN555wHwxhtvcPjhh7Pnnnuy++67c+ONN364N8TMSursQ8fS0KfXZusa+vTi7EPHliWeujjF7Ki+1t2z/ilTpnD++efz8Y9/nIMPPphp06YxceJEpk2bxo033sg+++zD2rVraWho4LLLLgNgyZIlPPPMM0yZMoXnnnsOSL45PPHEEwwcOJC5c+eybNkyHn30USKCo446igceeICWlhaGDh3K3XffDcDrr7/+Id4NMyu1Qp7xqJ4SyqO+tvXWW7Nw4UIefPBBFixYwLRp0/jmN7/JkCFD2GeffQDYdtttAXjooYc47bTTANhll10YOXLkpsR/yCGHMHDgQADmzp3L3LlzGT9+PADr169n2bJl7L///px11lmcc845HHHEEey///7djtvMymPq+GFlS/St1UXiz6u+1qtXLyZPnszkyZMZN24cl19+eZvDKjua7KZ///6bbXfuuedy0kknfWC7hQsXcs8993DuuecyZcoUvvOd73yo2M2sftVFjT+P+tqzzz7LsmXLNi0//vjj7LrrrqxYsYLHHnsMgHXr1rFx40YOOOAArr32WgCee+45XnrpJcaO/eCxDz30UK6++mrWr18PQHNzM6tWrWLFihX069eP448/nrPOOotFixZ1O24zs7o448+jvrZ+/XpOO+001qxZQ+/evdl5552ZNWsWJ5xwAqeddhobNmygoaGBX/3qV5xyyimcfPLJjBs3jt69e3PNNddsuihcbMqUKSxdupSJEycCSTnpZz/7Gb///e85++yz2WKLLejTpw9XXHFFt+M2M6uKOXcbGxuj9UQsS5cuZddddy1TRJXJ74mZFZO0MCIaW6+vi1KPmZm9L9fEL+l0SU9KekrSGem6gZLulbQs/b1dnjGYmdnmckv8knYHvgpMAPYEjpA0BpgJzIuIMcC8dLlbqqFMVSp+L8wsqzzP+HcFHo6INyNiI3A/8HfA0cDsdJvZwNTu7Lxv37689tprTni834+/b9++5Q7FzKpAnqN6ngQukLQ9sAH4DNAE7BgRKwEiYqWkHdp6saQZwAyAESNGfOD54cOHs3z5cvegTxVm4DIz60xuiT8ilkq6GLgXWA/8DtjYhdfPAmZBMqqn9fN9+vTxbFNmZt2Q6zj+iLgKuApA0r8By4FXJA1Jz/aHAKvyjMHMrNrkPVtX3qN6dkh/jwCOAa4H7gCmp5tMB27PMwYzs2qSRzfh1vIex/9zSU8DdwKnRsRq4CLgEEnLgEPSZTMzozSzdeVd6vlAG8mIeA04KM/jmplVq1LM1uU7d83MKkh7XYN7crYuJ34zq3pzFjcz6aL5jJ55N5Mumt+j9fBSK8VsXXXRndPMalfhYmihLl64GApUzMQnXVGK2bqc+M2squUxtWq55T1blxO/mVWd4nHu7TVt6cmLobXGid/Mqkrr0k57evJiaK3xxV0zqyptlXZa6+mLobXGZ/xmVlU6KuEIcrkYWmuc+M2sqgwd0EBzG8l/2IAGfj3zwDJEVH1c6jGzqlKKce61zmf8ZlZVSjHOvdY58ZtZ1cl7nHutc6nHzKzOOPGbmdUZl3rMzIrkPftVJXDiNzNL1VrDt/bkPfXi1yU9JelJSddL6itptKRHJC2TdKOkLfOMwcwsq1LMflUJckv8koYBXwMaI2J3oBdwHHAxcGlEjAFWAyfmFYOZWVeUYvarSpD3xd3eQIOk3kA/YCVwIHBL+vxsYGrOMZiZZVKK2a8qQW6JPyKage8DL5Ek/NeBhcCaiNiYbrYcaLNwJmmGpCZJTS0tLXmFaWa2Sb3cFZxnqWc74GhgNDAU6A8c1sambbbTjohZEdEYEY2DBw/OK0wzs02mjh/GhceMY9iABkTS/+fCY8bV1IVdyHdUz8HAHyOiBUDSrcB+wABJvdOz/uHAihxjMDPrknq4KzjPGv9LwL6S+kkScBDwNLAA+Gy6zXTg9hxjMDOzVvKs8T9CchF3EbAkPdYs4BzgTEm/B7YHrsorBjMz+6Bcb+CKiPOA81qtfh6YkOdxzcysfe7VY2ZWZ9yywcy6rR762tQiJ34z65Z66WtTi1zqMbNuqZe+NrXIZ/xm1i310temWK2UtnzGb2bdUi99bQoKpa3mNRsI3i9tzVncXO7QusyJ38y6pV762hTUUmnLpR4z65ZCiaMWSh9Z1FJpy4nfzLqtHvraFAwd0EBzG0m+GktbLvWYmWVQS6Utn/GbmWVQS6UtJ34zs4xqpbTlUo+ZWZ3JlPgljZR0cPq4QdI2+YZlZmZ56TTxS/oqSV/9n6SrhgNz8gzKzMzyk+WM/1RgErAWICKWATvkGZSZmeUnS+L/S0S8XViQ1Jt2JkgvJmmspMeLftZKOkPSQEn3SlqW/t7uw/wBZmbWNVkS//2SvgE0SDoEuBm4s7MXRcSzEbFXROwFfBJ4E7gNmAnMi4gxwLx02czMSiRL4p8JtJDMm3sScA/wrS4e5yDgDxHxInA0MDtdPxuY2sV9mZnZh9DhOH5JvYDZEXE88NMPcZzjgOvTxztGxEqAiFgpydcLzKxmWh5Xgw7P+CPiXWCwpC27e4D0tUeRlIi68roZkpokNbW0tHT38GZWBWqp5XE1yFLqeQH4taRvSzqz8NOFYxwGLIqIV9LlVyQNAUh/r2rrRRExKyIaI6Jx8ODBXTicmVWbWmp5XA2yJP4VwF3pttsU/WT1Od4v8wDcAUxPH08Hbu/CvsysBtVSy+Nq0Gmvnoj4HkB6t25ExPqsO5fUDziE5KJwwUXATZJOBF4Cju1SxGZWc2qp5XE16DTxS9od+F9gYLr8KvCliHiqs9dGxJvA9q3WvUYyysfMeki1Xxg9+9CxnHvrks3KPdXa8rgaZOnOOQs4MyIWAEiaTDLCZ78c4zKzjAoXRgtJs3BhFKia5F9LLY+rQZbE37+Q9AEi4j5J/XOMycy6oKMLo9WUOGul5XE1yJL4n5f0bZJyD8DxwB/zC8nMusIXRq2rsozq+UdgMHBr+jMIOCHPoMwsu/YugPrCqLWn08QfEasj4msRsXf6c0ZErC5FcGbWuVqaC9ZKI0s//nslDSha3k7SL/MNy8yymjp+GBceM45hAxoQMGxAAxceM871cmtXlhr/oIhYU1iIiNXur2NWWXxh1LoiS43/PUkjCguSRpKhH7+ZmVWmLGf83wQeknR/unwAMCO/kMzMLE9ZWjb8QtLewL7pqq9HxKv5hmVmZnlpt9QjaaSkjwCkif4Nkr47X/owbZrNzKy8Oqrx3wT0B5C0F0k//ZeAPYEf5R+amZnloaNST0NErEgfHw9cHRH/LmkL4PH8QzOzgmpvwmaVpaMzfhU9PpBkYnQi4r1cIzKzzXh2KutpHSX++ZJuknQZsB0wHzbNmvV2KYIzM89OZT2vo1LPGcA0YAjw6Yh4J13/UZIhnmZWAm7CZj2t3cQfEQHc0Mb6xblGZGab8exU1tOy3LnbbZIGSLpF0jOSlkqaKGlg2v9nWfp7uzxjMKsUcxY3M+mi+YyeeTeTLpqfuUbvJmzW03JN/MBlwC8iYheSYaBLgZnAvIgYQ3LBeGbOMZiV3Ye5QOsmbNbTlFR0OtlIagBGRETmq0mStgV+B3wsig4i6VlgckSsTC8U3xcRHZ66NDY2RlNTU9ZDm1WcSRfNb7NcM2xAA7+eeWAZIrJ6IGlhRDS2Xp+lLfORJOP2f5Eu7yXpjgzH/BjQAvy3pMWSrkynbNwxIlYCpL/b7PQpaYakJklNLS0tGQ5nVrl8gdYqSZZSz3eBCcAagIh4HBiV4XW9gb2BKyJiPEnLh8xlnYiYFRGNEdE4ePDgrC8zq0ieJcsqSZbEvzEiXu/GvpcDyyPikXT5FpIPglfSEk/hnoBV3di3WVXxBVqrJFkS/5OSPg/0kjRG0n8Bv+nsRRHxJ+BlSYV/2QcBTwN3ANPTddOB27setll18QVaqySdXtyV1I/khq0pJG0cfgn8a0S81enOk+ZuVwJbAs+TTNK+BUkDuBEkTd+OjYg/d7QfX9w1M+u69i7uZhrVU25O/GZmXdde4u90IhZJd/LBqRZfB5qAn2Q58zczs8qRpcb/PLAe+Gn6sxZ4Bfh4umxmZlUky5y74yPigKLlOyU9EBEHSHoqr8DMzCwfWc74B0saUVhIHw9KF92e2cysymQ54/9n4CFJfyAZ1TMaOCW9C3d2nsGZmVnP6zTxR8Q9ksYAu5Ak/meKLuj+IM/gzMys52U54wcYA4wF+gJ7SCIi/ie/sMxKx/PZWr3JMpzzPGAysBtwD3AY8BDgxG9Vr9AuuTC1YaFdMuDkbzUry8Xdz5K0W/hTRJxA0ld/q1yjMisRz2dr9ShL4t8QEe8BG9Me+6tIWi6bVT23S7Z6lCXxN0kaQHKz1kJgEfBorlGZlYjbJVs96jTxR8QpEbEmIn4MHAJMT0s+ZlXP7ZKtHmWZgWte4XFEvBARTxSvM6tmbpds9ajdUT2S+gL9gEGStiMZww+wLTC0BLGZlcTU8cOc6K2udDSc8yTgDJIkv5D3E/9a4PKc4zIzs5y0m/gj4jLgMkmnRcR/lTAmMzPLUZaWDf8laT+SCdZ7F63v9AYuSS8A64B3SebubZQ0ELgx3d8LwD9ExOpuxG5mZt2Q5eLu/wLfBz4N7JP+fGBGlw78TUTsVTQLzExgXkSMAealy2ZmViJZevU0ArtFz83ReDRJCwhIunveB5zTQ/s2M7NOZLmB60ngo93cfwBzJS2UNCNdt2NErARIf+/Q1gslzZDUJKmppaWlm4c3M7PWspzxDwKelvQo8JfCyog4KsNrJ0XECkk7APdKeiZrYBExC5gFyWTrWV9nZmYdy5L4v9vdnUfEivT3Kkm3AROAVyQNiYiVkoaQ9P4xM7MSydKy4X6S0Td90sePkfTr6ZCk/pK2KTwGppCUje4ApqebTQdu71bkZmbWLVn68X8VmAEMBP4KGAb8mKRVc0d2BG6TVDjOdRHxC0mPATdJOhF4CTi2++GbmVlXZSn1nEpSonkEICKWpTX7DkXE8yS9+1uvf43OPzTMKpJn67JakCXx/yUi3k7P3JHUm2S0jlld8WxdViuyDOe8X9I3gAZJhwA3A3fmG5ZZ5fFsXVYrsiT+mUALsISkcds9wLfyDMqsEnm2LqsVWUo9DcDVEfFTAEm90nVv5hmYWaUZOqCB5jaSvGfrsmqT5Yx/HkmiL2gAfpVPOGaVy7N1Wa3IcsbfNyLWFxYiYr2kfjnGZFaRChdwParHql2WxP+GpL0jYhGApE8CLmpaXfJsXVYLsiT+04GbJa1Il4cA0/ILyczM8tRh4pe0BbAlsAswlmT6xWci4p0SxGZmZjnoMPFHxHuS/j0iJpL02TEzsyqXZVTPXEl/r8Ktu2ZmVtWy1PjPBPoD70raQFLuiYjYNtfIzMwsF1kmW9+mFIFY5XJjMrPakmWydUk6XtK30+WdJE3IPzSrBIXGZM1rNhC835hszuLmcodmZt2Upcb/I2Ai8Pl0eT1weW4RWUWp1sZkcxY3M+mi+YyeeTeTLprvDyqzIllq/J+KiL0lLQaIiNWStsw5LqsQ1diYzO2TzTqW5Yz/nbQxWwBIGgy8l/UAknpJWizprnR5tKRHJC2TdKM/RCpbew3IKrkxWbV+SzErlSyJ/z+B24AdJF0APAT8WxeOcTqwtGj5YuDSiBgDrAZO7MK+rMSqsTFZNX5LMSulLJOtXwv8C3AhsBKYGhE3Z9m5pOHA4cCV6bKAA4Fb0k1mA1O7HraVytTxw7jwmHEMG9CAgGEDGrjwmHEVXTKpxm8pZqXUbo1fUl/gZGBnkklYfhIRG7u4/x+QfGgUhoRuD6wp2s9yksnbrYJVW2Oysw8du1mNHyr/W4pZKXV0xj8baCRJ+ocB3+/KjiUdAayKiIXFq9vYtM35eyXNkNQkqamlpaUrh7Y6V43fUsxKSRFtz5suaUlEjEsf9wYejYi9M+9YuhD4IrAR6AtsS3Kt4FDgoxGxUdJE4LsRcWhH+2psbIympqashzYzM0DSwohobL2+ozP+TR04u1HiISLOjYjhETEKOA6YHxFfABYAn003mw7c3tV9m5lZ93WU+PeUtDb9WQfsUXgsae2HOOY5wJmSfk9S87/qQ+zLzMy6qN2LuxHRq73nuioi7gPuSx8/D7jlg5lZmWQZx29mZjXEid/MrM448ZuZ1RknfjOzOpOlO6dZj/CELmaVwYnfSsKtks0qh0s9VhJulWxWOZz4rSTcKtmscjjxW0m4VbJZ5XDit5KoxgldzGqVL+5aSRQu4HpUj1n5OfFbyVTbhC5mtcqlHjOzOuPEb2ZWZ5z4zczqjBO/mVmdceI3M6szuY3qkdQXeADYKj3OLRFxnqTRwA3AQGAR8MWIeDuvOGpJR03OytUAzY3XzKpPnsM5/wIcGBHrJfUBHpL0f8CZwKURcYOkHwMnAlfkGEdN6KjJGVCWBmhuvGZWnXIr9URifbrYJ/0J4EDglnT9bGBqXjHUko6anJWrAZobr5lVp1xr/JJ6SXocWAXcC/wBWBMRG9NNlgNtnhpKmiGpSVJTS0tLnmFWhY6anJWrAZobr5lVp1wTf0S8GxF7AcOBCcCubW3WzmtnRURjRDQOHjw4zzCrQkdNzsrVAM2N18yqU0lG9UTEGuA+YF9ggKTCtYXhwIpSxFDtOmpyVq4GaG68Zlad8hzVMxh4JyLWSGoADgYuBhYAnyUZ2TMduD2vGGpJliZnpR5d48ZrZtVJEW1WWj78jqU9SC7e9iL5ZnFTRJwv6WO8P5xzMXB8RPylo301NjZGU1NTLnGamdUqSQsjorH1+tzO+CPiCWB8G+ufJ6n3W4Xy2Hyz2ua2zLYZj803q31u2WCb8dh8s9rnxG+b8dh8s9rnxG+b8dh8s9rnxF8j5ixuZtJF8xk9824mXTSfOYubu7Ufj803q32+uFsDevKCrMfmm9U+J/4eVo6hkB1dkO3OsT0pulltc+LvQeUaCukLsmbWFa7x96ByDYX0BVkz6won/h5UrjNvX5A1s65w4u9B5Trznjp+GBceM45hAxoQMGxAAxceM851ejNrk2v8PejsQ8duVuOH0p15+4KsmWXlxN+DPBTSzKqBE38P85m3mVU6J/4q4nbJZtYTnPirhNslm1lPyW1Uj6SdJC2QtFTSU5JOT9cPlHSvpGXp7+3yiqG7eqrvTU9yu2Qz6yl5DufcCPxzROxKMsn6qZJ2A2YC8yJiDDAvXa4YhTPr5jUbCN4/sy538vfduWbWU3JL/BGxMiIWpY/XAUuBYcDRJHPxkv6emlcM3VGpZ9a+O9fMekpJbuCSNIpk/t1HgB0jYiUkHw7ADu28ZoakJklNLS0tpQgTqNwza9+da2Y9JffEL2lr4OfAGRGxNuvrImJWRDRGROPgwYPzC7CVSj2z9t25ZtZTch3VI6kPSdK/NiJuTVe/ImlIRKyUNARYlWcMXVXOu28743sEzKwn5DmqR8BVwNKI+I+ip+4ApqePpwO35xVDd/jM2sxqnSIinx1LnwYeBJYA76Wrv0FS578JGAG8BBwbEX/uaF+NjY3R1NSUS5xmZrVK0sKIaGy9PrdST0Q8BKidpw/K67gFvsvVzKxtNXnnru9yNTNrX03246/UsfhmZpWgJhN/pY7FNzOrBDWZ+Ct1LL6ZWSWoycTvu1zNzNpXkxd3PROWmVn7ajLxg+9yNTNrT02WeszMrH1O/GZmdcaJ38yszjjxm5nVGSd+M7M6k1t3zp4kqQV4MePmg4BXcwynuyoxrkqMCRxXV1RiTFCZcVViTJBvXCMj4gMzWVVF4u8KSU1ttSEtt0qMqxJjAsfVFZUYE1RmXJUYE5QnLpd6zMzqjBO/mVmdqcXEP6vcAbSjEuOqxJjAcXVFJcYElRlXJcYEZYir5mr8ZmbWsVo84zczsw448ZuZ1ZmaSfySrpa0StKT5Y6lQNJOkhZIWirpKUmnlzsmAEl9JT0q6XdpXN8rd0wFknpJWizprnLHUiDpBUlLJD0uqanc8RRIGiDpFknPpP/GJpY5nrHpe1T4WSvpjHLGVCDp6+m/9SclXS+pbwXEdHoaz1Olfp9qpsYv6QBgPfA/EbF7ueMBkDQEGBIRiyRtAywEpkbE02WOS0D/iFgvqQ/wEHB6RDxczrgAJJ0JNALbRsQR5Y4HksQPNEZERd38I2k28GBEXClpS6BfRKwpd1yQfIADzcCnIiLrzZd5xTKM5N/4bhGxQdJNwD0RcU0ZY9oduAGYALwN/AL4p4hYVorj18wZf0Q8APy53HEUi4iVEbEofbwOWAqUfZKASKxPF/ukP2U/A5A0HDgcuLLcsVQ6SdsCBwBXAUTE25WS9FMHAYc3FB4AAAVDSURBVH8od9Iv0htokNQb6AesKHM8uwIPR8SbEbERuB/4u1IdvGYSf6WTNAoYDzxS3kgSaUnlcWAVcG9EVEJcPwD+BXiv3IG0EsBcSQslzSh3MKmPAS3Af6elsSsl9S93UEWOA64vdxAAEdEMfB94CVgJvB4Rc8sbFU8CB0jaXlI/4DPATqU6uBN/CUjaGvg5cEZErC13PAAR8W5E7AUMByakXz3LRtIRwKqIWFjOONoxKSL2Bg4DTk3LiuXWG9gbuCIixgNvADPLG1IiLTsdBdxc7lgAJG0HHA2MBoYC/SUdX86YImIpcDFwL0mZ53fAxlId34k/Z2kN/efAtRFxa7njaS0tD9wH/G2ZQ5kEHJXW028ADpT0s/KGlIiIFenvVcBtJHXZclsOLC/6pnYLyQdBJTgMWBQRr5Q7kNTBwB8joiUi3gFuBfYrc0xExFURsXdEHEBSpi5JfR+c+HOVXkS9ClgaEf9R7ngKJA2WNCB93EDyP8Yz5YwpIs6NiOERMYqkTDA/Isp6VgYgqX96YZ60lDKF5Gt6WUXEn4CXJY1NVx0ElHXQQJHPUSFlntRLwL6S+qX/Tx5Ecr2trCTtkP4eARxDCd+zmplsXdL1wGRgkKTlwHkRcVV5o2IS8EVgSVpPB/hGRNxTxpgAhgCz05EXWwA3RUTFDJ+sMDsCtyX5gt7AdRHxi/KGtMlpwLVpaeV54IQyx0Narz4EOKncsRRExCOSbgEWkZRTFlMZ7Rt+Lml74B3g1IhYXaoD18xwTjMzy8alHjOzOuPEb2ZWZ5z4zczqjBO/mVmdceI3M6szTvxWlSStb7X8ZUk/LOHx95X0SNqFcqmk76brJ0vq8s1Bkq6R9Nn08ZWSduvCaydXUjdTq3w1M47frCdI6hUR72bYdDbwDxHxu/R+iMKNVJNJusT+prsxRMRXuvtasyx8xm81R9JISfMkPZH+HpGu33RWnS6vT39PTudNuI7kZrv+ku5O5yt4UtK0Ng6zA0nDr0Lfo6fTRnwnA19Pvwns38ExJemHkp6WdHe6v8I290lqTB9PkfRbSYsk3Zz2fULS3yrpw/8QyV2fZpk58Vu1alDRpB/A+UXP/ZBkXoY9gGuB/8ywvwnANyNiN5K+RSsiYs90boe27tS9FHhW0m2STpLUNyJeAH4MXBoRe0XEgx0c7+9IviWMA75KG71jJA0CvgUcnDaJawLOVDKJyE+BI4H9gY9m+PvMNnHit2q1IU2ue6VdRr9T9NxE4Lr08f8Cn86wv0cj4o/p4yXAwZIulrR/RLzeeuOIOJ9kwpi5wOdp+8OhIwcA16ffFlYA89vYZl9gN+DX6YfbdGAksAtJ07Flkdx6XxHN7Kx6OPFbPSj0JdlI+m8+bda1ZdE2b2zaOOI54JMkHwAXSir+UKFouz9ExBUkTb/2TPuutNbRMTvrlyKSuRIKH3C7RcSJGV9r1i4nfqtFvyHp8AnwBZJp9wBeIEnokPRn79PWiyUNBd6MiJ+RTODxgXbHkg5PEznAGOBdYA2wDtimaNP2jvkAcFw6Ic4Q4G/aCOVhYJKkndNj9pP0cZJOqqMl/VW63efa+jvM2uNRPVaLvgZcLelsklmqCl0rfwrcLulRYB5FZ/mtjAMukfQeSefEf2pjmy8Cl0p6k+Ss/gsR8a6kO4FbJB1N0j2zvWPeBhxI8q3iOZKp9zYTES2SvgxcL2mrdPW3IuI5JTOB3S3pVZIPtoqYZ9qqg7tzmpnVGZd6zMzqjBO/mVmdceI3M6szTvxmZnXGid/MrM448ZuZ1RknfjOzOvP/6LiLEqE9e/cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(x='Hours', y='Scores', style='o')  \n",
    "plt.title('Hours vs Percentage')  \n",
    "plt.xlabel('Hours Studied')  \n",
    "plt.ylabel('Percentage Score')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OBSERVATION: we can clearly observe that as the number of hours are increasing the percentage score is also increasing.\n",
    "###### CONCLUSION: Both are positively correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset for training :  x= Dependent variable , y= independent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values  \n",
    "y = data.iloc[:, 1].values  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### checking the dataset and lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5],\n",
       "       [5.1],\n",
       "       [3.2],\n",
       "       [8.5],\n",
       "       [3.5],\n",
       "       [1.5],\n",
       "       [9.2],\n",
       "       [5.5],\n",
       "       [8.3],\n",
       "       [2.7],\n",
       "       [7.7],\n",
       "       [5.9],\n",
       "       [4.5],\n",
       "       [3.3],\n",
       "       [1.1],\n",
       "       [8.9],\n",
       "       [2.5],\n",
       "       [1.9],\n",
       "       [6.1],\n",
       "       [7.4],\n",
       "       [2.7],\n",
       "       [4.8],\n",
       "       [3.8],\n",
       "       [6.9],\n",
       "       [7.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= X.reshape(-1, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21],\n",
       "       [47],\n",
       "       [27],\n",
       "       [75],\n",
       "       [30],\n",
       "       [20],\n",
       "       [88],\n",
       "       [60],\n",
       "       [81],\n",
       "       [25],\n",
       "       [85],\n",
       "       [62],\n",
       "       [41],\n",
       "       [42],\n",
       "       [17],\n",
       "       [95],\n",
       "       [30],\n",
       "       [24],\n",
       "       [67],\n",
       "       [69],\n",
       "       [30],\n",
       "       [54],\n",
       "       [35],\n",
       "       [76],\n",
       "       [86]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= y.reshape(-1, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X: 25\n",
      "length of y: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"length of X:\" ,len(X))\n",
    "print(\"length of y:\" ,len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### since we have 25 values each we can use 20 for trainning and 5 for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 5/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=test_size, random_state=0) \n",
    "print(\"split done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train: 20\n",
      "length of X_test: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"length of X_train:\" ,len(X_train))\n",
    "print(\"length of X_test:\" ,len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building logistic Regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression model built.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression  \n",
    "linear = LinearRegression()  \n",
    "linear.fit(X_train, y_train) \n",
    "\n",
    "print(\"logistic regression model built.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking your model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours Scores pred_Scores\n",
      "[1.5] [20] [16.88414476]\n",
      "[3.2] [27] [33.73226078]\n",
      "[7.4] [69] [75.357018]\n",
      "[2.5] [30] [26.79480124]\n",
      "[5.9] [62] [60.49103328]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hours\", \"Scores\", \"pred_Scores\")\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i],y_test[i],y_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking MAE   (Better to check MAE than accuracy as we are dealing with very less data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 4.183859899002975\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predicting percentage for 9.25 hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Hours = 9.25\n",
      "Predicted Score = [93.69173249]\n"
     ]
    }
   ],
   "source": [
    "hours = 9.25\n",
    "\n",
    "model_pred = linear.predict([[hours]])\n",
    "print(\"No of Hours = {}\".format(hours))\n",
    "print(\"Predicted Score = {}\".format(model_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copy_X', 'fit_intercept', 'n_jobs', 'normalize'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### applying Random forest and Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### fitting Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predicting for gradient Boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = GBoost.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours Scores pred_Scores\n",
      "[1.5] [20] 17.07191660647004\n",
      "[3.2] [27] 41.820113735352834\n",
      "[7.4] [69] 84.98590925291927\n",
      "[2.5] [30] 21.207107461213862\n",
      "[5.9] [62] 67.00659744798398\n"
     ]
    }
   ],
   "source": [
    "print(\"Hours\", \"Scores\", \"pred_Scores\")\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i],y_test[i],y_pred1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 9.506719273714435\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predicting for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours Scores pred_Scores\n",
      "[1.5] [20] 19.090833333333332\n",
      "[3.2] [27] 37.77083333333333\n",
      "[7.4] [69] 84.43\n",
      "[2.5] [30] 23.380833333333335\n",
      "[5.9] [62] 63.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Hours\", \"Scores\", \"pred_Scores\")\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i],y_test[i],y_pred2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7.087833333333334\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### random forest with hyper parameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### change the cell type to \"code\" to run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best params.\n",
    "\n",
    "{'n_estimators': 800,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_random = rf_random.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred3 = best_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred3 values : array([28.40875893, 30.7529375 , 27.89338393, 63.35      , 19.8230625 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = [28.40875893, 30.7529375 , 27.89338393, 63.35      , 19.8230625 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours Scores pred_Scores\n",
      "[1.5] [20] 28.40875893\n",
      "[3.2] [27] 30.7529375\n",
      "[7.4] [69] 27.89338393\n",
      "[2.5] [30] 63.35\n",
      "[5.9] [62] 19.8230625\n"
     ]
    }
   ],
   "source": [
    "print(\"Hours\", \"Scores\", \"pred_Scores\")\n",
    "for i in range(len(X_test)):\n",
    "    print(X_test[i],y_test[i],y_pred3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 25.759050000000002\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for logistic regression: 4.183859899002975\n",
      "Mean Absolute Error for Gradient boosting: 9.506719273714435\n",
      "Mean Absolute Error for Random Forest: 7.087833333333334\n",
      "Mean Absolute Error for Random forest with tuning: 25.759050000000002\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error for logistic regression:', metrics.mean_absolute_error(y_test, y_pred)) \n",
    "print('Mean Absolute Error for Gradient boosting:', metrics.mean_absolute_error(y_test, y_pred1)) \n",
    "print('Mean Absolute Error for Random Forest:', metrics.mean_absolute_error(y_test, y_pred2)) \n",
    "print('Mean Absolute Error for Random forest with tuning:', metrics.mean_absolute_error(y_test, y_pred3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conclusion: logistic Regression is best (high end models may not be the best models all the time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Lazy Regressor to see performance of other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = LazyRegressor(ignore_warnings= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 56.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:03:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model,preds = all.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.39</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.59</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.61</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.94</td>\n",
       "      <td>4.82</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>0.93</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>0.92</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.91</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.84</td>\n",
       "      <td>8.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.83</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.81</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.80</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.79</td>\n",
       "      <td>9.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.72</td>\n",
       "      <td>10.46</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>0.71</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.70</td>\n",
       "      <td>10.83</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.70</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>0.34</td>\n",
       "      <td>16.20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.28</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>20.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>23.43</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>23.43</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>23.43</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-1.22</td>\n",
       "      <td>29.68</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-3.19</td>\n",
       "      <td>40.74</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-5.96</td>\n",
       "      <td>52.52</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               R-Squared  RMSE  Time Taken\n",
       "Model                                                     \n",
       "Ridge                               0.95  4.39        0.01\n",
       "Lasso                               0.95  4.41        0.01\n",
       "ElasticNetCV                        0.95  4.48        0.05\n",
       "LassoCV                             0.95  4.51        0.06\n",
       "SGDRegressor                        0.95  4.59        0.01\n",
       "RidgeCV                             0.95  4.61        0.01\n",
       "BayesianRidge                       0.95  4.63        0.01\n",
       "LassoLarsIC                         0.95  4.65        0.01\n",
       "LarsCV                              0.95  4.65        0.01\n",
       "Lars                                0.95  4.65        0.01\n",
       "LassoLarsCV                         0.95  4.65        0.01\n",
       "OrthogonalMatchingPursuit           0.95  4.65        0.00\n",
       "LinearRegression                    0.95  4.65        0.01\n",
       "RANSACRegressor                     0.95  4.65        0.01\n",
       "TransformedTargetRegressor          0.95  4.65        0.01\n",
       "HuberRegressor                      0.94  4.82        0.01\n",
       "LassoLars                           0.93  5.25        0.01\n",
       "PassiveAggressiveRegressor          0.92  5.80        0.01\n",
       "KNeighborsRegressor                 0.91  5.99        0.01\n",
       "AdaBoostRegressor                   0.84  8.06        0.06\n",
       "ElasticNet                          0.83  8.22        0.01\n",
       "BaggingRegressor                    0.81  8.70        0.02\n",
       "ExtraTreesRegressor                 0.80  8.93        0.08\n",
       "RandomForestRegressor               0.79  9.11        0.10\n",
       "XGBRegressor                        0.72 10.46        0.01\n",
       "ExtraTreeRegressor                  0.71 10.72        0.01\n",
       "GradientBoostingRegressor           0.70 10.83        0.02\n",
       "DecisionTreeRegressor               0.70 10.92        0.00\n",
       "GaussianProcessRegressor            0.34 16.20        0.01\n",
       "SVR                                 0.28 16.87        0.01\n",
       "NuSVR                              -0.01 20.02        0.01\n",
       "HistGradientBoostingRegressor      -0.38 23.43        0.02\n",
       "DummyRegressor                     -0.38 23.43        0.00\n",
       "LGBMRegressor                      -0.38 23.43        0.01\n",
       "LinearSVR                          -1.22 29.68        0.01\n",
       "MLPRegressor                       -3.19 40.74        0.08\n",
       "KernelRidge                        -5.96 52.52        0.01"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output of Best model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Hours = 9.25\n",
      "Predicted Score = [93.69173249]\n"
     ]
    }
   ],
   "source": [
    "hours = 9.25\n",
    "\n",
    "model_pred = linear.predict([[hours]])\n",
    "print(\"No of Hours = {}\".format(hours))\n",
    "print(\"Predicted Score = {}\".format(model_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### output of other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Hours = 9.25\n",
      "Predicted Score of GBoost = 88.06564088936018\n"
     ]
    }
   ],
   "source": [
    "hours = 9.25\n",
    "\n",
    "model_pred1 = GBoost.predict([[hours]])\n",
    "print(\"No of Hours = {}\".format(hours))\n",
    "print(\"Predicted Score of GBoost = {}\".format(model_pred1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Hours = 9.25\n",
      "Predicted Score of Random Forest = 88.72\n"
     ]
    }
   ],
   "source": [
    "hours = 9.25\n",
    "\n",
    "model_pred2 = rf.predict([[hours]])\n",
    "print(\"No of Hours = {}\".format(hours))\n",
    "print(\"Predicted Score of Random Forest = {}\".format(model_pred2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
